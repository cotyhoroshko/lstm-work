{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iMIecXvof-M",
        "outputId": "7f0d47fa-68d0-48e6-cb81-51f5d23317ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18dcc2W6okYi",
        "outputId": "042f8fb9-50bc-421b-9539-77b0eb83b972"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlstm\n",
            "  Downloading xlstm-1.0.5-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlstm-1.0.5-py3-none-any.whl (95 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.3/95.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlstm\n",
            "Successfully installed xlstm-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ninja-build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ECPjJ0qQ98",
        "outputId": "f23fd123-97c3-4467-ede6-76a20ff43b24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  ninja-build\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 111 kB of archives.\n",
            "After this operation, 358 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ninja-build amd64 1.10.1-1 [111 kB]\n",
            "Fetched 111 kB in 0s (315 kB/s)\n",
            "Selecting previously unselected package ninja-build.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../ninja-build_1.10.1-1_amd64.deb ...\n",
            "Unpacking ninja-build (1.10.1-1) ...\n",
            "Setting up ninja-build (1.10.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "VZFRE38noukT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xlstm import (\n",
        "    xLSTMBlockStack,\n",
        "    xLSTMBlockStackConfig,\n",
        "    mLSTMBlockConfig,\n",
        "    mLSTMLayerConfig,\n",
        "    sLSTMBlockConfig,\n",
        "    sLSTMLayerConfig,\n",
        "    FeedForwardConfig,\n",
        ")\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os2nVu60orYK",
        "outputId": "e940aa30-4458-4570-f5d2-ddc309e45c6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 1"
      ],
      "metadata": {
        "id": "zpbG3KUMowSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження та попередня обробка даних\n",
        "path_to_dataset = \"/content/drive/MyDrive/diploma/datasets/HateSpeechDatasetBalanced.csv\"\n",
        "df = pd.read_csv(path_to_dataset)\n",
        "df = df.sample(frac=0.05, random_state=42)  # Використання частини даних для швидкості\n",
        "df = df[['Content', 'Label']]\n",
        "\n",
        "def preprocess(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "df['Content'] = df['Content'].apply(preprocess)"
      ],
      "metadata": {
        "id": "oTtYziFCovxA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Розділення на тренувальну та тестову вибірки\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Побудова словника\n",
        "all_words = [word for tweet in train_df['Content'] for word in tweet]\n",
        "vocab = sorted(set(all_words))\n",
        "word_to_idx = {word: idx+1 for idx, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab) + 1  # +1 для padding\n",
        "\n",
        "# Кодування твітів\n",
        "def encode_tweet(tweet):\n",
        "    return [word_to_idx[word] for word in tweet if word in word_to_idx]\n",
        "\n",
        "train_df['Content'] = train_df['Content'].apply(encode_tweet)\n",
        "test_df['Content'] = test_df['Content'].apply(encode_tweet)\n",
        "\n",
        "# Додавання padding\n",
        "def pad_sequences(sequences, max_len):\n",
        "    return np.array([seq + [0]*(max_len-len(seq)) if len(seq) < max_len else seq[:max_len] for seq in sequences])\n",
        "\n",
        "MAX_LEN = 100\n",
        "X_train = pad_sequences(train_df['Content'], MAX_LEN)\n",
        "X_test = pad_sequences(test_df['Content'], MAX_LEN)\n",
        "\n",
        "# Кодування міток\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(train_df['Label'])\n",
        "y_test = le.transform(test_df['Label'])\n",
        "\n",
        "# Створення датасетів та DataLoader\n",
        "class HateSpeechDataset(Dataset):\n",
        "    def __init__(self, tweets, labels):\n",
        "        self.tweets = tweets\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.tweets[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "train_dataset = HateSpeechDataset(X_train, y_train)\n",
        "test_dataset = HateSpeechDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "djTf-p_Po1wv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Конфігурація xLSTM\n",
        "cfg = xLSTMBlockStackConfig(\n",
        "    mlstm_block=mLSTMBlockConfig(\n",
        "        mlstm=mLSTMLayerConfig(\n",
        "            conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=4\n",
        "        )\n",
        "    ),\n",
        "    slstm_block=sLSTMBlockConfig(\n",
        "        slstm=sLSTMLayerConfig(\n",
        "            backend=\"vanilla\",\n",
        "            num_heads=4,\n",
        "            conv1d_kernel_size=4,\n",
        "            bias_init=\"powerlaw_blockdependent\",\n",
        "        ),\n",
        "        feedforward=FeedForwardConfig(proj_factor=1.3, act_fn=\"gelu\"),\n",
        "    ),\n",
        "    context_length=MAX_LEN,\n",
        "    num_blocks=7,\n",
        "    embedding_dim=128,\n",
        "    slstm_at=[1],\n",
        ")"
      ],
      "metadata": {
        "id": "itiv4B38o5J0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація xLSTM стеку\n",
        "xlstm_stack = xLSTMBlockStack(cfg).to(\"cuda\")"
      ],
      "metadata": {
        "id": "X3jqZnwZo9db"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель для виявлення мови ворожнечі\n",
        "class HateSpeechModel(nn.Module):\n",
        "    def __init__(self, xlstm_stack, vocab_size, embedding_dim):\n",
        "        super(HateSpeechModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.xlstm = xlstm_stack\n",
        "        self.fc = nn.Linear(embedding_dim, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.xlstm(x)\n",
        "        x = self.fc(x.mean(dim=1))\n",
        "        return x"
      ],
      "metadata": {
        "id": "mJVwZYSMrNED"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ініціалізація моделі\n",
        "model = HateSpeechModel(xlstm_stack, vocab_size, 128).to(\"cuda\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Z4v8dgKcrM-h"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Навчання моделі з прогрес-баром\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        # Додаємо прогрес-бар для епохи\n",
        "        for tweets, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            tweets, labels = tweets.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(tweets)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}')\n",
        "\n",
        "# Тестування моделі з прогрес-баром\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        # Додаємо прогрес-бар для тестування\n",
        "        for tweets, labels in tqdm(test_loader, desc='Testing'):\n",
        "            tweets, labels = tweets.to(\"cuda\"), labels.to(\"cuda\")\n",
        "            outputs = model(tweets)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    return all_preds"
      ],
      "metadata": {
        "id": "Gejtz2zvrM8C"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск навчання\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU15BrnkrM5E",
        "outputId": "9942c7bf-6d72-4aa6-d7de-fb8013e3e6fa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 454/454 [01:59<00:00,  3.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 211.7664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 454/454 [01:58<00:00,  3.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Loss: 147.6509\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 454/454 [01:57<00:00,  3.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Loss: 91.1941\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 454/454 [01:56<00:00,  3.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Loss: 55.3721\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 454/454 [01:57<00:00,  3.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Loss: 34.2970\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 454/454 [01:56<00:00,  3.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Loss: 26.9716\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 454/454 [01:56<00:00,  3.90it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Loss: 21.2874\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 454/454 [01:55<00:00,  3.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Loss: 14.4445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 454/454 [01:52<00:00,  4.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10], Loss: 14.9162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 454/454 [01:53<00:00,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 16.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = test_model(model, test_loader)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezBu0ps5rM2R",
        "outputId": "43b35c5b-e951-436d-d35a-50adb2ec0263"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 114/114 [00:08<00:00, 12.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/diploma/hate_speech_model.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyiiCKYpxlAX",
        "outputId": "d004aced-09bb-4786-be58-7a1b84afb82d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/diploma/hate_speech_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпорт моделі\n",
        "# model = HateSpeechModel(xlstm_stack, vocab_size, 128).to(\"cuda\")\n",
        "# model.load_state_dict(torch.load(model_save_path))\n",
        "# model.eval()\n",
        "# print(\"Model loaded and ready to use\")"
      ],
      "metadata": {
        "id": "pW0w6N0axk32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75j9ZioRrMzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oHvBQurqHqZ",
        "outputId": "4dd97029-a9aa-4a81-e051-f2f480da80c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwiwSbQTqHif",
        "outputId": "e2c32ea3-6d40-4755-ecf5-324ae2573048"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('/root/.cache/torch_extensions/py310_cu121')"
      ],
      "metadata": {
        "id": "LaQjWzmtqHW6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install --reinstall ninja-build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnoVrx5eq83D",
        "outputId": "750aa8d4-4ee2-4d8e-89f2-68fe89e0a248"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 1 reinstalled, 0 to remove and 49 not upgraded.\n",
            "Need to get 111 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ninja-build amd64 1.10.1-1 [111 kB]\n",
            "Fetched 111 kB in 0s (224 kB/s)\n",
            "(Reading database ... 123609 files and directories currently installed.)\n",
            "Preparing to unpack .../ninja-build_1.10.1-1_amd64.deb ...\n",
            "Unpacking ninja-build (1.10.1-1) over (1.10.1-1) ...\n",
            "Setting up ninja-build (1.10.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod -R 777 /root/.cache/torch_extensions/"
      ],
      "metadata": {
        "id": "WbCDQqhyq_qX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case 2"
      ],
      "metadata": {
        "id": "sN41tkfRoxkb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxHGV9QcoypX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}